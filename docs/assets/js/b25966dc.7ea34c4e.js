"use strict";(self.webpackChunkproject_api_docs=self.webpackChunkproject_api_docs||[]).push([[9558],{1781:(e,t,s)=>{s.r(t),s.d(t,{assets:()=>c,contentTitle:()=>d,default:()=>a,frontMatter:()=>r,metadata:()=>l,toc:()=>h});const l=JSON.parse('{"id":"research/visual-intelligence","title":"\ud83d\uddbc\ufe0f Visual Intelligence Providers","description":"\ud83d\uddbc\ufe0f  Visual Intelligence Providers (VIPs)","source":"@site/src/research/visual-intelligence.md","sourceDirName":"research","slug":"/research/visual-intelligence","permalink":"/research/visual-intelligence","draft":false,"unlisted":false,"editUrl":"https://github.com/vtempest/Svelte-Starter-DOCS/tree/master/src/research/visual-intelligence.md","tags":[],"version":"current","frontMatter":{},"sidebar":"default","previous":{"title":"\u2696\ufe0f SvelteKit vs Next.js","permalink":"/research/sveltekit_vs_nextjs_comparison"}}');var n=s(4848),i=s(8453);const r={},d="\ud83d\uddbc\ufe0f Visual Intelligence Providers",c={},h=[{value:"\ud83d\uddbc\ufe0f  Visual Intelligence Providers (VIPs)",id:"\ufe0f--visual-intelligence-providers-vips",level:2},{value:"\ud83c\udfad <strong>How Visual Models Work</strong>",id:"-how-visual-models-work",level:2},{value:"\ud83d\udcda <strong>Learning Resources</strong>:",id:"-learning-resources",level:2}];function o(e){const t={a:"a",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(t.header,{children:(0,n.jsx)(t.h1,{id:"\ufe0f-visual-intelligence-providers",children:"\ud83d\uddbc\ufe0f Visual Intelligence Providers"})}),"\n",(0,n.jsx)(t.h2,{id:"\ufe0f--visual-intelligence-providers-vips",children:"\ud83d\uddbc\ufe0f  Visual Intelligence Providers (VIPs)"}),"\n",(0,n.jsxs)(t.table,{children:[(0,n.jsx)(t.thead,{children:(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.th,{style:{textAlign:"left"},children:"\ud83c\udfa8 Provider"}),(0,n.jsx)(t.th,{style:{textAlign:"left"},children:"\ud83d\uddbc\ufe0f Model Families"}),(0,n.jsx)(t.th,{style:{textAlign:"left"},children:"\ud83d\udcda Docs"}),(0,n.jsx)(t.th,{style:{textAlign:"left"},children:"\ud83d\udd11 Keys"}),(0,n.jsx)(t.th,{style:{textAlign:"left"},children:"\ud83d\udcb0 Valuation"}),(0,n.jsx)(t.th,{style:{textAlign:"left"},children:"\ud83d\udcb8 Revenue (2024)"}),(0,n.jsx)(t.th,{style:{textAlign:"left"},children:"\ud83d\udcb2 Cost (1M Output)"})]})}),(0,n.jsxs)(t.tbody,{children:[(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.strong,{children:"OpenAI"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"DALL-E 3, DALL-E 2"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.a,{href:"https://help.openai.com/en/articles/6705023-dall-e-api-faq",children:"Docs"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.a,{href:"https://platform.openai.com/api-keys",children:"Keys"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$300B"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$3.7B"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$40.00"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.strong,{children:"Stability AI"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"Stable Diffusion XL, SD 2.1, SD 1.5"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.a,{href:"https://platform.stability.ai/docs",children:"Docs"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.a,{href:"https://platform.stability.ai/account/keys",children:"Keys"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$1B"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$50M"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$2.00"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.strong,{children:"Midjourney"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"Midjourney v6, v5, v4"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.a,{href:"https://docs.midjourney.com/",children:"Docs"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.a,{href:"https://www.midjourney.com/account/",children:"Keys"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$10B"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$200M"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$15.00"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.strong,{children:"Runway ML"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"Gen-4, Gen-3 Alpha, Gen-2"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.a,{href:"https://docs.dev.runwayml.com/",children:"Docs"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.a,{href:"https://app.runwayml.com/account",children:"Keys"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$1.5B"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$100M"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$10.00"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.strong,{children:"Pika Labs"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"Pika 1.0, Pika 2.0"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.a,{href:"https://pika.art/api",children:"Docs"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.a,{href:"https://pika.art/account",children:"Keys"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$500M"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$20M"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$50.00"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.strong,{children:"Leonardo AI"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"Leonardo Creative, Leonardo Select"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.a,{href:"https://docs.leonardo.ai/",children:"Docs"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.a,{href:"https://app.leonardo.ai/account",children:"Keys"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$200M"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$10M"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$8.00"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.strong,{children:"Synthesia"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"Synthesia STUDIO, Synthesia GO"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.a,{href:"https://docs.synthesia.io/",children:"Docs"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.a,{href:"https://app.synthesia.io/account",children:"Keys"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$1B"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$50M"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$25.00"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.strong,{children:"D-ID"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"D-ID Creative Reality Studio"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.a,{href:"https://www.d-id.com/api/",children:"Docs"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.a,{href:"https://studio.d-id.com/account",children:"Keys"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$300M"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$15M"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$20.00"})]}),(0,n.jsxs)(t.tr,{children:[(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.strong,{children:"Luma AI"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"Dream Machine, Genie"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.a,{href:"https://docs.lumalabs.ai/",children:"Docs"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:(0,n.jsx)(t.a,{href:"https://lumalabs.ai/account",children:"Keys"})}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$400M"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$25M"}),(0,n.jsx)(t.td,{style:{textAlign:"left"},children:"$12.00"})]})]})]}),"\n",(0,n.jsxs)(t.h2,{id:"-how-visual-models-work",children:["\ud83c\udfad ",(0,n.jsx)(t.strong,{children:"How Visual Models Work"})]}),"\n",(0,n.jsx)(t.p,{children:"Visual intelligence models transform text descriptions into images and videos through\ndiffusion processes that gradually refine noise into coherent visual content. These systems\nlearn from billions of image-text pairs, understanding relationships between language and\nvisual elements through transformer architectures with cross-attention mechanisms. The\ndiffusion process starts with pure noise and progressively denoises it over hundreds of\nsteps, guided by text embeddings that condition each denoising step. For video generation,\nmodels extend this process across temporal dimensions, maintaining consistency between\nframes while generating smooth motion sequences. The attention mechanisms allow models to\nfocus on relevant parts of both text prompts and visual features, enabling precise control\nover composition, style, and content. Advanced models like DALL-E 3 and Midjourney v6\nemploy sophisticated prompt understanding and artistic style matching, while video models\nlike Runway's Gen-4 can generate complex scenes with multiple moving elements and\nrealistic physics. The training process involves massive datasets of high-quality images\nand videos paired with descriptive text, teaching models to associate visual concepts\nwith linguistic descriptions and generate novel content that matches human artistic\nintentions and aesthetic preferences."}),"\n",(0,n.jsxs)(t.h2,{id:"-learning-resources",children:["\ud83d\udcda ",(0,n.jsx)(t.strong,{children:"Learning Resources"}),":"]}),"\n",(0,n.jsxs)(t.ul,{children:["\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://github.com/CompVis/stable-diffusion",children:"Stable Diffusion Training"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://arxiv.org/abs/2403.19649",children:"DALL-E 3 Technical Report"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://github.com/runwayml/stable-video-diffusion",children:"Video Generation Models"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://huggingface.co/docs/diffusers/index",children:"Diffusion Model Tutorial"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://pytorch.org/tutorials/beginner/deep_learning_computer_vision_tutorial.html",children:"Computer Vision Basics"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://github.com/AUTOMATIC1111/stable-diffusion-webui",children:"Image Generation Guide"})}),"\n",(0,n.jsx)(t.li,{children:(0,n.jsx)(t.a,{href:"https://github.com/THUDM/CogVideo",children:"Video Synthesis Overview"})}),"\n"]})]})}function a(e={}){const{wrapper:t}={...(0,i.R)(),...e.components};return t?(0,n.jsx)(t,{...e,children:(0,n.jsx)(o,{...e})}):o(e)}},8453:(e,t,s)=>{s.d(t,{R:()=>r,x:()=>d});var l=s(6540);const n={},i=l.createContext(n);function r(e){const t=l.useContext(i);return l.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function d(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(n):e.components||n:r(e.components),l.createElement(i.Provider,{value:t},e.children)}}}]);